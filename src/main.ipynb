{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "096cd9f0-0aee-4604-bfe3-820efe120ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "\n",
    "import os\n",
    "import re\n",
    "import spacy\n",
    "import nltk\n",
    "import unicodedata\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from dotenv import load_dotenv\n",
    "from langchain_community.document_loaders import CSVLoader\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_chroma import Chroma\n",
    "from util import dir_management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c879c2-b4a9-4dd7-b727-ee00d53320f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "\n",
    "import os\n",
    "import re\n",
    "import spacy\n",
    "import nltk\n",
    "import unicodedata\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from dotenv import load_dotenv\n",
    "from langchain_community.document_loaders import CSVLoader\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_chroma import Chroma\n",
    "from util import dir_management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de9bad1c-5497-4408-9821-26d680a5a1e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "\n",
    "load_dotenv()\n",
    "os.environ['LANGCHAIN_TRACING_V2'] = os.getenv('LANGCHAIN_TRACING_V2')\n",
    "os.environ['LANGCHAIN_API_KEY'] = os.getenv('LANGCHAIN_API_KEY')\n",
    "os.environ['GROQ_API_KEY'] = os.getenv('GROQ_API_KEY')\n",
    "llm = ChatGroq(model=\"llama3-8b-8192\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d143ce-235e-4b61-8947-b54cb4be2dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "\n",
    "def load_stopwords():\n",
    "    try:\n",
    "        return set(stopwords.words('portuguese'))\n",
    "    except LookupError:\n",
    "        nltk.download('stopwords')\n",
    "        return set(stopwords.words('portuguese'))\n",
    "\n",
    "\n",
    "stop_words = load_stopwords()\n",
    "\n",
    "nlp = spacy.load('pt_core_news_sm')\n",
    "\n",
    "csv_columns = ['product_name', 'site_category_lv1',\n",
    "               'site_category_lv2', 'overall_rating', 'review_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be0f1ab4-588e-4f0d-b077-3944433215b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text\n",
    "\n",
    "\n",
    "def remove_exclamations_and_periods(text):\n",
    "    text = re.sub(r'[!.,@]', '', text)\n",
    "    return text\n",
    "\n",
    "\n",
    "def remove_stop_words(text):\n",
    "    return ' '.join([word for word in text.split() if word not in stop_words])\n",
    "\n",
    "\n",
    "def remove_accents(text):\n",
    "    text = unicodedata.normalize('NFD', text)\n",
    "    text = re.sub(r'[\\u0300-\\u036f]', '', text)\n",
    "    return text\n",
    "\n",
    "\n",
    "def format_docs(docs):\n",
    "    return '\\n\\n'.join(doc.page_content for doc in docs)\n",
    "\n",
    "\n",
    "def remove_filling_words(text):\n",
    "    word_list = [\n",
    "        'de', 'a', 'o', 'do', 'da', 'em', 'para', 'com', 'na', 'por',\n",
    "        'uma', 'os', 'no', 'se', 'mas', 'as', 'dos', 'pois', 'né'\n",
    "    ]\n",
    "    return ' '.join([word for word in text.split() if word not in word_list])\n",
    "\n",
    "\n",
    "def remove_repetitive_words(text):\n",
    "    return re.sub(r'\\b(\\w+)( \\1)+\\b', '', text)\n",
    "\n",
    "\n",
    "def remove_repetitive_letters(text):\n",
    "    return re.sub(r'/(.)\\1{3,}/g', '', text)\n",
    "\n",
    "\n",
    "def batch_documents(documents, batch_size):\n",
    "    for i in range(0, len(documents), batch_size):\n",
    "        yield documents[i:i + batch_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfdcee09-d5f3-404f-9750-dc6a3867249f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-6-0a6814bacce7>:2: DtypeWarning: Columns (2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(os.path.join(\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "\n",
    "df = pd.read_csv(os.path.join(\n",
    "    dir_management.get_project_dir(), 'B2W-Reviews.csv'))\n",
    "df_reduced = df.drop(\n",
    "    columns=[col for col in df.columns if col not in csv_columns])\n",
    "\n",
    "for column in csv_columns:\n",
    "    df_reduced[column] = df_reduced[column].apply(lambda x: clean_text(str(x)))\n",
    "    df_reduced[column] = df_reduced[column].apply(\n",
    "        lambda x: remove_exclamations_and_periods(str(x)))\n",
    "    df_reduced[column] = df_reduced[column].apply(\n",
    "        lambda x: remove_accents(str(x)))\n",
    "    df_reduced[column] = df_reduced[column].apply(\n",
    "        lambda x: remove_stop_words(str(x)))\n",
    "\n",
    "df_reduced[\"review_text\"] = df_reduced[\"review_text\"].apply(\n",
    "    lambda x: remove_filling_words(str(x)))\n",
    "df_reduced[\"review_text\"] = df_reduced[\"review_text\"].apply(\n",
    "    lambda x: remove_repetitive_words(str(x)))\n",
    "df_reduced[\"review_text\"] = df_reduced[\"review_text\"].apply(\n",
    "    lambda x: remove_repetitive_letters(str(x)))\n",
    "\n",
    "result_file_name = f'B2W-Reviews-After-PLN.csv'\n",
    "df_reduced.sort_values('site_category_lv1').to_csv(\n",
    "    os.path.join(dir_management.get_out_dir(), result_file_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0236bd27-86c9-4f84-8b87-b43719e113a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "\n",
    "loader = CSVLoader(\n",
    "    file_path=os.path.join(dir_management.get_out_dir(), result_file_name),\n",
    "    encoding='utf-8',\n",
    "    csv_args={\n",
    "        'delimiter': ',',\n",
    "        'quotechar': '\"',\n",
    "        'fieldnames': csv_columns\n",
    "    }\n",
    ")\n",
    "\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c1147df-2bb4-4658-9729-70c84d7f82fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Projetos\\Testes_IA\\API-FATEC-6-SEM-IA\\venv\\lib\\site-packages\\sentence_transformers\\cross_encoder\\CrossEncoder.py:13: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm, trange\n",
      "c:\\Projetos\\Testes_IA\\API-FATEC-6-SEM-IA\\venv\\lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000, chunk_overlap=200)\n",
    "splits = text_splitter.split_documents(docs)\n",
    "\n",
    "model_name = 'sentence-transformers/all-MiniLM-L6-v2'\n",
    "model_kwargs = {'device': 'cpu'}\n",
    "encode_kwargs = {'normalize_embeddings': False}\n",
    "hf = HuggingFaceEmbeddings(\n",
    "    model_name=model_name,\n",
    "    model_kwargs=model_kwargs,\n",
    "    encode_kwargs=encode_kwargs\n",
    ")\n",
    "\n",
    "max_batch_size = 3000\n",
    "vector_db_path = os.path.join(dir_management.get_project_dir(), 'chroma_db')\n",
    "if  not os.path.exists(vector_db_path):\n",
    "    vectorstore = Chroma(\n",
    "        embedding_function=hf,\n",
    "        collection_name='reviews',\n",
    "        persist_directory=vector_db_path\n",
    "    )\n",
    "\n",
    "    for batch in batch_documents(splits, max_batch_size):\n",
    "        vectorstore.add_texts(\n",
    "            texts=[doc.page_content for doc in batch],\n",
    "            metadatas=[doc.metadata for doc in batch]\n",
    "        )\n",
    "\n",
    "else:\n",
    "    vectorstore = Chroma(\n",
    "        embedding_function=hf,\n",
    "        collection_name='reviews',\n",
    "        persist_directory=vector_db_path\n",
    "    )\n",
    "\n",
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07bea4be-279a-4268-b091-959349e88d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "\n",
    "prompt_template = \"\"\"\n",
    "\n",
    "Responda sempre de forma clara e precisa em português do Brasil.\n",
    "Você é um assistente especializado em marketing e feedback de clientes. Responda perguntas que estejam relacionadas a marketing, campanhas, review de clientes, avaliações de produtos ou publicidade. \n",
    "Para perguntas fora desse escopo, responda: \"Essa pergunta está fora do escopo deste chatbot. Por favor, faça perguntas relacionadas a marketing.\"\n",
    "Para perguntas sobre produtos, use apenas o feedback dos clientes fornecido no contexto para responder, não invente respostas. Se o contexto não tiver informações suficientes, responda: \"Não há informações suficientes para responder a essa pergunta.\"\n",
    "\n",
    "Contexto: {context}\n",
    "Pergunta: {question}\n",
    "\n",
    "Resposta:\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "128af9f1-c8ee-4ccf-a897-dfcbb32036d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "\n",
    "def custom_prompt(context, question):\n",
    "    return prompt_template.format(context=context, question=question)\n",
    "\n",
    "# RAG Chain com prompt customizado\n",
    "\n",
    "\n",
    "def run_rag_chain(question):\n",
    "    # Recupera documentos e formata o contexto\n",
    "    retrieved_docs = retriever.invoke(question)  # aumentar para k=10 para ver o resultado \n",
    "    formatted_context = format_docs(retrieved_docs)\n",
    "\n",
    "    # Cria o prompt customizado\n",
    "    full_prompt = custom_prompt(formatted_context, question)\n",
    "\n",
    "    # Passa o prompt para o modelo de linguagem\n",
    "    response = llm.invoke(full_prompt)\n",
    "\n",
    "    # Parseia a resposta para o formato correto\n",
    "    parsed_response = StrOutputParser().parse(response)\n",
    "\n",
    "    return parsed_response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b66413-5b9d-42f6-8793-c3e2074537d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Essa pergunta está fora do escopo deste chatbot. Por favor, faça perguntas relacionadas a marketing.\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "\n",
    "response = run_rag_chain('Me fale sobre o clima de amanhã.')\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5919cec7-6983-4399-bbde-f5365c0ce42b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A avaliação do cliente apresentada revela que a experiência com a loja americana foi frustante devido à falta de profissionalismo e eficiência no atendimento ao cliente. Além disso, a entrega demorou para chegar e o produto não atendeu às expectativas do consumidor.\n",
      "\n",
      "Para melhorar a experiência do cliente, sugiero que a loja considere implementar os seguintes pontos:\n",
      "\n",
      "1. Treinamento para os distribuidores para que eles possam atender aos clientes de forma profissional e eficiente;\n",
      "2. Estabelecer um prazo de entrega mais preciso para que os consumidores possam planejar melhor;\n",
      "3. Melhorar a comunicação com os clientes antes e após a entrega, para que eles sejam informados sobre o status do pedido e qualquer problema que surja;\n",
      "4. Oferecer opções de entrega mais rápidas e flexíveis para atender às necessidades dos clientes;\n",
      "5. Revisar a política de devolução e troca de produtos para garantir que os clientes sejam satisfeitos com a compra.\n",
      "\n",
      "Além disso, a loja também pode considerar desenvolver um programa de feedback contínuo para coletar informações dos clientes e identificar áreas de melhoria, garantindo que as necessidades e expectativas dos clientes sejam atendidas.\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "\n",
    "response = run_rag_chain(\n",
    "    \"Como podemos melhorar a experiência do cliente com base nas avaliações recebidas?\")\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
